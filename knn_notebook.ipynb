{"nbformat": 4, "nbformat_minor": 5, "metadata": {}, "cells": [{"id": "3f56d550", "cell_type": "markdown", "source": "# K-Nearest Neighbors (KNN) \u2013 Beginner Notebook", "metadata": {}}, {"id": "faf64c82", "cell_type": "markdown", "source": "## 1. What is KNN?\nK-Nearest Neighbors is a simple ML algorithm that predicts output based on the closest data points in the dataset.", "metadata": {}}, {"id": "dd956210", "cell_type": "markdown", "source": "## 2. Distance Calculation\nMost common: Euclidean distance", "metadata": {}}, {"id": "9cbf2e57", "cell_type": "markdown", "source": "\n\\[\nd = \\sqrt{(x_1 - y_1)^2 + (x_2 - y_2)^2 + ... + (x_n - y_n)^2}\n\\]\n", "metadata": {}}, {"id": "284450b1", "cell_type": "markdown", "source": "## 3. Why Scaling?\nFeatures with larger numeric ranges dominate distance calculations, so scaling helps.", "metadata": {}}, {"id": "f146a8fc", "cell_type": "markdown", "source": "## 4. KNN Classification Example (Iris Dataset)", "metadata": {}}, {"id": "cd46ddc3", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "\nfrom sklearn.datasets import load_iris\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\n\n# Load data\ndata = load_iris()\nX = data.data\ny = data.target\n\n# Train-test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n\n# Scaling\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# Model\nknn = KNeighborsClassifier(n_neighbors=5)\nknn.fit(X_train, y_train)\n\n# Prediction\ny_pred = knn.predict(X_test)\n\n# Accuracy\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\n", "outputs": []}, {"id": "9c322238", "cell_type": "markdown", "source": "## 5. Choosing Best K \u2013 Elbow Method", "metadata": {}}, {"id": "9605f673", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "\nimport matplotlib.pyplot as plt\nfrom sklearn.neighbors import KNeighborsClassifier\n\nerror = []\n\nfor k in range(1, 21):\n    knn = KNeighborsClassifier(n_neighbors=k)\n    knn.fit(X_train, y_train)\n    pred = knn.predict(X_test)\n    error.append(1 - accuracy_score(y_test, pred))\n\nplt.plot(range(1, 21), error, marker='o')\nplt.xlabel(\"K value\")\nplt.ylabel(\"Error rate\")\nplt.title(\"Elbow Method\")\nplt.show()\n", "outputs": []}, {"id": "36647f59", "cell_type": "markdown", "source": "## 6. KNN Regression Example (California Housing)", "metadata": {}}, {"id": "2ed4704a", "cell_type": "code", "metadata": {}, "execution_count": null, "source": "\nfrom sklearn.datasets import fetch_california_housing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.metrics import mean_squared_error\n\n# Load dataset\ndata = fetch_california_housing()\nX = data.data\ny = data.target\n\n# Split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n\n# Scale features\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# Model\nknn_reg = KNeighborsRegressor(n_neighbors=5)\nknn_reg.fit(X_train, y_train)\n\n# Prediction\ny_pred = knn_reg.predict(X_test)\n\n# Evaluate\nmse = mean_squared_error(y_test, y_pred)\nprint(\"MSE:\", mse)\nprint(\"RMSE:\", mse ** 0.5)\n", "outputs": []}]}